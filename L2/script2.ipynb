{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "902c768a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r ../requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ca90a732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "from razdel import sentenize\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "38dfa437",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "model_name = \"sarahai/ru-sum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "acdd0f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MT5ForConditionalGeneration(\n",
       "  (shared): Embedding(250112, 512)\n",
       "  (encoder): MT5Stack(\n",
       "    (embed_tokens): Embedding(250112, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-7): 7 x MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): MT5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): MT5Stack(\n",
       "    (embed_tokens): Embedding(250112, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerCrossAttention(\n",
       "            (EncDecAttention): MT5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-7): 7 x MT5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): MT5LayerSelfAttention(\n",
       "            (SelfAttention): MT5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): MT5LayerCrossAttention(\n",
       "            (EncDecAttention): MT5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): MT5LayerFF(\n",
       "            (DenseReluDense): MT5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): MT5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): MT5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=250112, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "c135fab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def abstractive_summary(text, max_symbols=300):\n",
    "#     inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n",
    "#     summary_ids = model.generate(\n",
    "#           **inputs,\n",
    "#           max_length=100,\n",
    "#           min_length=60,\n",
    "#           num_beams=30,\n",
    "#           repetition_penalty=3.0,\n",
    "#           length_penalty=1.2,\n",
    "#           no_repeat_ngram_size=10,\n",
    "#           early_stopping=True\n",
    "#       )\n",
    "#     summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "#     return summary[:max_symbols]\n",
    "\n",
    "\n",
    "def improved_abstractive_summary(text, max_symbols=300, device='cuda'):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512).to('mps')\n",
    "    with torch.no_grad():\n",
    "        summary_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_length=100,          # подогнал под размер 300 на глаз\n",
    "            min_length=60,\n",
    "            num_beams=30,            # взял прямо жирно, но так мне больше нравится\n",
    "            temperature=0.9,         # Для чуть большей вариативности\n",
    "            repetition_penalty=1.5,  # Мягче штрафуем повторения\n",
    "            length_penalty=1.0,      # Нейтральное влияние на длину\n",
    "            no_repeat_ngram_size=3,  \n",
    "            early_stopping=True,\n",
    "            do_sample=True          \n",
    "        )\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    return summary[:max_symbols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "40975343",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing texts: 100%|██████████| 5/5 [01:20<00:00, 16.02s/it]\n"
     ]
    }
   ],
   "source": [
    "with open(\"ex2.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    texts = json.load(f)\n",
    "\n",
    "summaries = []\n",
    "for text in tqdm(texts, desc=\"Summarizing texts\"):\n",
    "    abs_summary = improved_abstractive_summary(text)\n",
    "    summaries.append(abs_summary)\n",
    "\n",
    "with open(\"summaries.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(summaries, f, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "ec338ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длинна исходного текста: 1054, Длинна реферата: 167, Длинна референса: 271\n",
      "Длинна исходного текста: 1101, Длинна реферата: 186, Длинна референса: 221\n",
      "Длинна исходного текста: 807, Длинна реферата: 196, Длинна референса: 281\n",
      "Длинна исходного текста: 684, Длинна реферата: 170, Длинна референса: 257\n",
      "Длинна исходного текста: 740, Длинна реферата: 246, Длинна референса: 198\n"
     ]
    }
   ],
   "source": [
    "reference_summaries = [\n",
    "    \"В избушке живёт пёс Дик, который любит наблюдать, как курят. Он обжорлив и любит есть рыбью требуху. Однажды автор собрал чернику на болоте и пытался научить Дика уму, показывая, как есть ягоды с куста. Через два дня пёс собрал чернику вокруг избушки, чему автор был рад.\",\n",
    "    \"Скворец Петруша любит подражать голосам и звукам. Поэт сочинял стихи и печатал их в журналах. В песне Петруши есть трели, свисты и рулады, которые звучат как весенние природные явления, принося радость и настроение весны.\",\n",
    "    \"Зайцы обычно не собирают букеты, ведь у каждого из них есть свой цветок — хвост. Но один заяц собрал настоящий букет и не знает, кому его подарить. Лисе и волку цветы не нужны, мишка любит ягоды, а барсук может даже наброситься. Решают отдать букет барсуку и посмотреть, что будет.\",\n",
    "    \"Ночью у костра главного героя охватывает страх. Ему кажется, что кто-то наблюдает из темноты и шепчется вокруг. После громкого крика появляется шум листьев — это шевеление листобоя в кронах деревьев. Рассказ передает атмосферу тревоги и таинственности леса.\",\n",
    "    \"В ночь в печной трубе задул листобой — холодный октябрьский ветер. Форточка была уже раскрыта настежь и полна берёзовых листьев. Листья сбрасывала берёза под окном, а сам хозяин уже скрылся куда-то.\"\n",
    "]\n",
    "\n",
    "for i in range(len(texts)):\n",
    "    print(f\"Длинна исходного текста: {len(texts[i])}, Длинна реферата: {len(summaries[i])}, Длинна референса: {len(reference_summaries[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "143dd8d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Результаты для пары 1:\n",
      "ROUGE-1: {'r': 0.21052631578947367, 'p': 0.2857142857142857, 'f': 0.24242423753902673}\n",
      "ROUGE-2: {'r': 0.045454545454545456, 'p': 0.06896551724137931, 'f': 0.05479451575905465}\n",
      "ROUGE-L: {'r': 0.21052631578947367, 'p': 0.2857142857142857, 'f': 0.24242423753902673}\n",
      "\n",
      "Результаты для пары 2:\n",
      "ROUGE-1: {'r': 0.5161290322580645, 'p': 0.5925925925925926, 'f': 0.5517241329548158}\n",
      "ROUGE-2: {'r': 0.3939393939393939, 'p': 0.48148148148148145, 'f': 0.43333332838333327}\n",
      "ROUGE-L: {'r': 0.5161290322580645, 'p': 0.5925925925925926, 'f': 0.5517241329548158}\n",
      "\n",
      "Результаты для пары 3:\n",
      "ROUGE-1: {'r': 0.1590909090909091, 'p': 0.23333333333333334, 'f': 0.18918918436815207}\n",
      "ROUGE-2: {'r': 0.020833333333333332, 'p': 0.034482758620689655, 'f': 0.02597402127846265}\n",
      "ROUGE-L: {'r': 0.1590909090909091, 'p': 0.23333333333333334, 'f': 0.18918918436815207}\n",
      "\n",
      "Результаты для пары 4:\n",
      "ROUGE-1: {'r': 0.25, 'p': 0.3, 'f': 0.27272726776859507}\n",
      "ROUGE-2: {'r': 0.05555555555555555, 'p': 0.06896551724137931, 'f': 0.0615384565964501}\n",
      "ROUGE-L: {'r': 0.25, 'p': 0.3, 'f': 0.27272726776859507}\n",
      "\n",
      "Результаты для пары 5:\n",
      "ROUGE-1: {'r': 0.8, 'p': 0.6153846153846154, 'f': 0.6956521689981097}\n",
      "ROUGE-2: {'r': 0.6333333333333333, 'p': 0.48717948717948717, 'f': 0.5507246327662256}\n",
      "ROUGE-L: {'r': 0.7333333333333333, 'p': 0.5641025641025641, 'f': 0.6376811545053561}\n"
     ]
    }
   ],
   "source": [
    "from rouge import Rouge\n",
    "\n",
    "rouge = Rouge()\n",
    "\n",
    "for i, (summary, reference) in enumerate(zip(summaries, reference_summaries)):\n",
    "    score = rouge.get_scores(summary, reference, avg=False)\n",
    "    print(f\"\\nРезультаты для пары {i+1}:\")\n",
    "    print(f\"ROUGE-1: {score[0]['rouge-1']}\")\n",
    "    print(f\"ROUGE-2: {score[0]['rouge-2']}\")\n",
    "    print(f\"ROUGE-L: {score[0]['rouge-l']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
